{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyPicjyH+1wl6nlf4Qp7grSG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.datasets import imdb\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, Reshape\n","from tensorflow.keras.models import Model\n","import numpy as np\n","\n","\n","# Load the IMDB word index\n","word_index = imdb.get_word_index()\n","# Reverse the word index to map integer indices to words\n","reverse_word_index = {value: key for (key, value) in word_index.items()}\n","# Add padding, start, and unknown tokens\n","reverse_word_index[0] = '<PAD>'\n","reverse_word_index[1] = '<START>'\n","reverse_word_index[2] = '<UNK>'\n","\n","# Parameters\n","vocab_size = 10000  # Size of the vocabulary\n","max_length = 100    # Maximum length of input sentences\n","latent_dim = 32     # Size of the latent space\n","embedding_dim = 50  # Embedding dimension\n","epochs = 10         # Number of training epochs\n","\n","# Load IMDB dataset\n","(x_train, _), (x_test, _) = imdb.load_data(num_words=vocab_size)\n","x_train = pad_sequences(x_train, maxlen=max_length, padding='post')\n","x_test = pad_sequences(x_test, maxlen=max_length, padding='post')\n","\n","# AutoEncoder Model\n","# Encoder\n","inputs = Input(shape=(max_length,))\n","embedded = Embedding(vocab_size, embedding_dim)(inputs)\n","flattened = Flatten()(embedded)\n","encoded = Dense(latent_dim, activation='relu')(flattened)\n","encoder_model = Model(inputs, encoded)\n","\n","# Decoder\n","latent_inputs = Input(shape=(latent_dim,))\n","reconstructed = Dense(max_length*embedding_dim, activation='relu')(latent_inputs)\n","reshaped = Reshape((max_length, embedding_dim))(reconstructed)\n","decoded = Dense(vocab_size, activation='softmax')(reshaped)\n","decoder_model = Model(latent_inputs, decoded)\n","\n","# Autoencoder\n","autoencoder = Model(inputs, decoder_model(encoder_model(inputs)))\n","autoencoder.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n","\n","# Train the model\n","autoencoder.fit(x_train, x_train,\n","                epochs=epochs,\n","                batch_size=32,\n","                validation_data=(x_test, x_test))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oAm4FBuHzOAU","executionInfo":{"status":"ok","timestamp":1707968659928,"user_tz":180,"elapsed":109700,"user":{"displayName":"Axel Sirota","userId":"02089179879199828401"}},"outputId":"4b3c612e-cdde-46c9-a456-0319a3b8d0ec"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","782/782 [==============================] - 32s 40ms/step - loss: 6.3560 - val_loss: 6.1398\n","Epoch 2/10\n","782/782 [==============================] - 10s 13ms/step - loss: 6.0839 - val_loss: 5.9375\n","Epoch 3/10\n","782/782 [==============================] - 9s 11ms/step - loss: 5.8803 - val_loss: 5.8522\n","Epoch 4/10\n","782/782 [==============================] - 8s 10ms/step - loss: 5.7808 - val_loss: 5.7740\n","Epoch 5/10\n","782/782 [==============================] - 7s 10ms/step - loss: 5.7021 - val_loss: 5.7384\n","Epoch 6/10\n","782/782 [==============================] - 8s 10ms/step - loss: 5.6522 - val_loss: 5.7143\n","Epoch 7/10\n","782/782 [==============================] - 8s 10ms/step - loss: 5.6130 - val_loss: 5.6954\n","Epoch 8/10\n","782/782 [==============================] - 8s 10ms/step - loss: 5.5822 - val_loss: 5.6828\n","Epoch 9/10\n","782/782 [==============================] - 8s 10ms/step - loss: 5.5576 - val_loss: 5.6748\n","Epoch 10/10\n","782/782 [==============================] - 7s 9ms/step - loss: 5.5365 - val_loss: 5.6693\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7d3f2179dc00>"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# Usage example (after training)\n","encoded_texts = encoder_model.predict(x_test[:10])\n","decoded_texts = decoder_model.predict(encoded_texts)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ry-bV1t5zUAG","executionInfo":{"status":"ok","timestamp":1707968659929,"user_tz":180,"elapsed":13,"user":{"displayName":"Axel Sirota","userId":"02089179879199828401"}},"outputId":"8277e76c-7d57-45ff-a4dd-01eaa10a4a5b"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7d3f20341e10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 48ms/step\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7d3f206035b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 73ms/step\n"]}]},{"cell_type":"code","source":["def decode_sequence(sequence):\n","    \"\"\"Decode a sequence of integers back to words.\"\"\"\n","    return ' '.join([reverse_word_index.get(i - 3, '?') for i in sequence])\n","\n","# Assume `decoded_texts` is the output from the decoder\n","decoded_sequences = np.argmax(decoded_texts, axis=-1)\n","\n","# Convert each sequence in the decoded_sequences back to text\n","decoded_texts = [decode_sequence(seq) for seq in decoded_sequences]\n","\n","# Example: print the first decoded text\n","print(decoded_texts[0])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y78OsRn0zYuy","executionInfo":{"status":"ok","timestamp":1707968659931,"user_tz":180,"elapsed":10,"user":{"displayName":"Axel Sirota","userId":"02089179879199828401"}},"outputId":"3cd2ab76-d3f5-416e-eb78-496500b94f70"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["? this is this movie is ? <UNK> this ? ? in <START> movie of <START> movie is is ? <START> movie of br ? ? ? ? a <START> <START> <UNK> br ? is ? ? ? ? ? <START> ? in ? ? <START> ? <UNK> ? ? <UNK> <START> ? <UNK> ? <START> <UNK> <START> ? <START> <START> br br br br ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"_xaLTDm72zjC","executionInfo":{"status":"ok","timestamp":1707968659931,"user_tz":180,"elapsed":7,"user":{"displayName":"Axel Sirota","userId":"02089179879199828401"}}},"execution_count":10,"outputs":[]}]}