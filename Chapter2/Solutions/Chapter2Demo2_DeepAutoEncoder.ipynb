{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyPwyIglzo3RnBc2mZSKXt3j"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3uNofyYd4GtD","executionInfo":{"status":"ok","timestamp":1709313647086,"user_tz":180,"elapsed":7903,"user":{"displayName":"Axel Sirota","userId":"02089179879199828401"}},"outputId":"978339d3-ec40-4db7-9af5-7edcf3764646"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n","2110848/2110848 [==============================] - 1s 1us/step\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 100)]             0         \n","                                                                 \n"," embedding (Embedding)       (None, 100, 100)          1000000   \n","                                                                 \n"," bidirectional (Bidirection  (None, 100, 512)          731136    \n"," al)                                                             \n","                                                                 \n"," dropout (Dropout)           (None, 100, 512)          0         \n","                                                                 \n"," bidirectional_1 (Bidirecti  (None, 256)               656384    \n"," onal)                                                           \n","                                                                 \n"," dense (Dense)               (None, 64)                16448     \n","                                                                 \n","=================================================================\n","Total params: 2403968 (9.17 MB)\n","Trainable params: 2403968 (9.17 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["import numpy as np\n","from tensorflow.keras.datasets import reuters\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, LSTM, RepeatVector, TimeDistributed, Embedding, Dropout, Bidirectional\n","from tensorflow.keras.datasets import imdb\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.optimizers import Adam\n","\n","# Parameters\n","vocab_size = 10000\n","max_seq_length = 100  # Maximum length of sequences\n","embedding_dim = 100   # Size of word embeddings\n","latent_dim = 64     # Size of the latent space\n","rnn_cells_first = 256  # Number of cells in the first RNN layer\n","rnn_cells_second = 128  # Number of cells in the second RNN layer\n","epochs = 100\n","batch_size = 256\n","\n","# Load Reuters dataset\n","(x_train, _), (x_test, _) = reuters.load_data(num_words=vocab_size)\n","x_train = pad_sequences(x_train, maxlen=max_seq_length, padding='post')\n","x_test = pad_sequences(x_test, maxlen=max_seq_length, padding='post')\n","\n","\n","# Encoder\n","input_text = Input(shape=(max_seq_length,))\n","x = Embedding(vocab_size, embedding_dim)(input_text)\n","x = Bidirectional(LSTM(rnn_cells_first, return_sequences=True))(x)\n","x = Dropout(0.15)(x)\n","x = Bidirectional(LSTM(rnn_cells_second))(x)\n","latent_repr = Dense(latent_dim, activation='relu')(x)\n","encoder_model = Model(input_text, latent_repr)\n","encoder_model.summary()"]},{"cell_type":"code","source":["\n","# Decoder\n","decoder_input = Input(shape=(latent_dim,))\n","decoder_x = Dense(max_seq_length * embedding_dim, activation='relu')(decoder_input)\n","decoder_x = RepeatVector(max_seq_length)(decoder_x)\n","decoder_x = LSTM(rnn_cells_second, return_sequences=True)(decoder_x)\n","decoder_x = Dropout(0.15)(decoder_x)\n","decoder_x = LSTM(rnn_cells_first, return_sequences=True)(decoder_x)\n","decoder_output = TimeDistributed(Dense(vocab_size, activation='softmax'))(decoder_x)\n","decoder_model = Model(decoder_input, decoder_output)\n","decoder_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gQDW3kRo6MvF","executionInfo":{"status":"ok","timestamp":1709313647712,"user_tz":180,"elapsed":628,"user":{"displayName":"Axel Sirota","userId":"02089179879199828401"}},"outputId":"2d5ab28f-0f3d-4a55-ec28-73e6d4d71e0d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 64)]              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 10000)             650000    \n","                                                                 \n"," repeat_vector (RepeatVecto  (None, 100, 10000)        0         \n"," r)                                                              \n","                                                                 \n"," lstm_2 (LSTM)               (None, 100, 128)          5186048   \n","                                                                 \n"," dropout_1 (Dropout)         (None, 100, 128)          0         \n","                                                                 \n"," lstm_3 (LSTM)               (None, 100, 256)          394240    \n","                                                                 \n"," time_distributed (TimeDist  (None, 100, 10000)        2570000   \n"," ributed)                                                        \n","                                                                 \n","=================================================================\n","Total params: 8800288 (33.57 MB)\n","Trainable params: 8800288 (33.57 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["\n","# Autoencoder\n","autoencoder = Model(input_text, decoder_model(encoder_model(input_text)))\n","autoencoder.compile(optimizer=Adam(learning_rate=0.0005), loss='sparse_categorical_crossentropy')\n","autoencoder.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RfGA489U6NyB","executionInfo":{"status":"ok","timestamp":1709313651516,"user_tz":180,"elapsed":1576,"user":{"displayName":"Axel Sirota","userId":"02089179879199828401"}},"outputId":"6ed8c463-8217-4937-f2d4-76b524dea459"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 100)]             0         \n","                                                                 \n"," model (Functional)          (None, 64)                2403968   \n","                                                                 \n"," model_1 (Functional)        (None, 100, 10000)        8800288   \n","                                                                 \n","=================================================================\n","Total params: 11204256 (42.74 MB)\n","Trainable params: 11204256 (42.74 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","import tensorflow.keras.backend as K\n","\n","def custom_lr_scheduler(epoch, lr):\n","    # Decrease learning rate by 0.1 factor every 5 epochs\n","    if epoch % 5 == 0 and epoch != 0:\n","        lr = lr * 0.1\n","    return lr\n","\n","# Define the callback\n","lr_scheduler = LearningRateScheduler(custom_lr_scheduler)\n","\n","early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","# Train the model\n","autoencoder.fit(x_train, x_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, x_test), callbacks=[early_stopping, lr_scheduler])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lYT_XZcn6Fen","executionInfo":{"status":"ok","timestamp":1709313876133,"user_tz":180,"elapsed":209729,"user":{"displayName":"Axel Sirota","userId":"02089179879199828401"}},"outputId":"308b7b3f-a8ee-41ef-a127-650c14afa6a1"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","36/36 [==============================] - 23s 310ms/step - loss: 7.4231 - val_loss: 5.7901 - lr: 5.0000e-04\n","Epoch 2/100\n","36/36 [==============================] - 8s 235ms/step - loss: 5.7929 - val_loss: 5.7549 - lr: 5.0000e-04\n","Epoch 3/100\n","36/36 [==============================] - 7s 199ms/step - loss: 5.7625 - val_loss: 5.7419 - lr: 5.0000e-04\n","Epoch 4/100\n","36/36 [==============================] - 6s 178ms/step - loss: 5.7400 - val_loss: 5.7107 - lr: 5.0000e-04\n","Epoch 5/100\n","36/36 [==============================] - 8s 215ms/step - loss: 5.6983 - val_loss: 5.6966 - lr: 5.0000e-04\n","Epoch 6/100\n","36/36 [==============================] - 8s 212ms/step - loss: 5.6634 - val_loss: 5.6493 - lr: 5.0000e-05\n","Epoch 7/100\n","36/36 [==============================] - 7s 194ms/step - loss: 5.6517 - val_loss: 5.6439 - lr: 5.0000e-05\n","Epoch 8/100\n","36/36 [==============================] - 6s 182ms/step - loss: 5.6463 - val_loss: 5.6396 - lr: 5.0000e-05\n","Epoch 9/100\n","36/36 [==============================] - 6s 178ms/step - loss: 5.6420 - val_loss: 5.6370 - lr: 5.0000e-05\n","Epoch 10/100\n","36/36 [==============================] - 6s 171ms/step - loss: 5.6386 - val_loss: 5.6333 - lr: 5.0000e-05\n","Epoch 11/100\n","36/36 [==============================] - 6s 163ms/step - loss: 5.6348 - val_loss: 5.6310 - lr: 5.0000e-06\n","Epoch 12/100\n","36/36 [==============================] - 6s 162ms/step - loss: 5.6343 - val_loss: 5.6306 - lr: 5.0000e-06\n","Epoch 13/100\n","36/36 [==============================] - 5s 153ms/step - loss: 5.6339 - val_loss: 5.6302 - lr: 5.0000e-06\n","Epoch 14/100\n","36/36 [==============================] - 5s 154ms/step - loss: 5.6333 - val_loss: 5.6298 - lr: 5.0000e-06\n","Epoch 15/100\n","36/36 [==============================] - 5s 141ms/step - loss: 5.6329 - val_loss: 5.6294 - lr: 5.0000e-06\n","Epoch 16/100\n","36/36 [==============================] - 5s 141ms/step - loss: 5.6324 - val_loss: 5.6293 - lr: 5.0000e-07\n","Epoch 17/100\n","36/36 [==============================] - 5s 150ms/step - loss: 5.6327 - val_loss: 5.6293 - lr: 5.0000e-07\n","Epoch 18/100\n","36/36 [==============================] - 5s 137ms/step - loss: 5.6326 - val_loss: 5.6293 - lr: 5.0000e-07\n","Epoch 19/100\n","36/36 [==============================] - 5s 133ms/step - loss: 5.6323 - val_loss: 5.6292 - lr: 5.0000e-07\n","Epoch 20/100\n","36/36 [==============================] - 5s 137ms/step - loss: 5.6324 - val_loss: 5.6291 - lr: 5.0000e-07\n","Epoch 21/100\n","36/36 [==============================] - 5s 141ms/step - loss: 5.6323 - val_loss: 5.6291 - lr: 5.0000e-08\n","Epoch 22/100\n","36/36 [==============================] - 5s 133ms/step - loss: 5.6322 - val_loss: 5.6291 - lr: 5.0000e-08\n","Epoch 23/100\n","36/36 [==============================] - 5s 145ms/step - loss: 5.6323 - val_loss: 5.6291 - lr: 5.0000e-08\n","Epoch 24/100\n","36/36 [==============================] - 5s 133ms/step - loss: 5.6321 - val_loss: 5.6291 - lr: 5.0000e-08\n","Epoch 25/100\n","36/36 [==============================] - 4s 124ms/step - loss: 5.6323 - val_loss: 5.6291 - lr: 5.0000e-08\n","Epoch 26/100\n","36/36 [==============================] - 4s 124ms/step - loss: 5.6321 - val_loss: 5.6291 - lr: 5.0000e-09\n","Epoch 27/100\n","36/36 [==============================] - 5s 136ms/step - loss: 5.6322 - val_loss: 5.6291 - lr: 5.0000e-09\n","Epoch 28/100\n","36/36 [==============================] - 4s 124ms/step - loss: 5.6323 - val_loss: 5.6291 - lr: 5.0000e-09\n","Epoch 29/100\n","36/36 [==============================] - 4s 123ms/step - loss: 5.6323 - val_loss: 5.6291 - lr: 5.0000e-09\n","Epoch 30/100\n","36/36 [==============================] - 4s 124ms/step - loss: 5.6321 - val_loss: 5.6291 - lr: 5.0000e-09\n","Epoch 31/100\n","36/36 [==============================] - 5s 132ms/step - loss: 5.6320 - val_loss: 5.6291 - lr: 5.0000e-10\n","Epoch 32/100\n","36/36 [==============================] - 5s 132ms/step - loss: 5.6324 - val_loss: 5.6291 - lr: 5.0000e-10\n","Epoch 33/100\n","36/36 [==============================] - 4s 120ms/step - loss: 5.6324 - val_loss: 5.6291 - lr: 5.0000e-10\n","Epoch 34/100\n","36/36 [==============================] - 4s 123ms/step - loss: 5.6323 - val_loss: 5.6291 - lr: 5.0000e-10\n","Epoch 35/100\n","36/36 [==============================] - 5s 125ms/step - loss: 5.6326 - val_loss: 5.6291 - lr: 5.0000e-10\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7a8be43e09a0>"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# Encode the input text using the encoder model\n","encoded_texts = encoder_model.predict(x_test[:10])\n","\n","# Decode the encoded texts using the decoder model\n","# This gives you a probability distribution for each word in the sequence\n","prob_distributions = decoder_model.predict(encoded_texts)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rKv2NwBG4Nc-","executionInfo":{"status":"ok","timestamp":1709316447009,"user_tz":180,"elapsed":642,"user":{"displayName":"Axel Sirota","userId":"02089179879199828401"}},"outputId":"5ec1740a-a3cf-478d-b2e5-dc21aa59587a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 23ms/step\n"]}]},{"cell_type":"code","source":["def sample(preds, temperature=1.0):\n","    # Convert to array and prevent numerical issues with very small numbers\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds + 1e-7) / temperature  # Adjust by temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)  # Softmax\n","    probas = np.random.multinomial(1, preds, 1)  # Sample from the softmax distribution\n","    return np.argmax(probas)\n"],"metadata":{"id":"97e44eGbBIz6","executionInfo":{"status":"ok","timestamp":1709316447471,"user_tz":180,"elapsed":3,"user":{"displayName":"Axel Sirota","userId":"02089179879199828401"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["word_index = reuters.get_word_index()\n","reverse_word_index = {value: key for (key, value) in word_index.items()}\n","def decode_sequence_with_sampling(prob_distributions, temperature=1.0):\n","    return ' '.join([reverse_word_index.get(sample(probs, temperature) - 3, '?') for probs in prob_distributions])\n","\n","# Example usage with a specified temperature\n","temperature = 1  # Adjust this value to change randomness\n","decoded_texts = [decode_sequence_with_sampling(seq, temperature) for seq in prob_distributions]\n","for text in decoded_texts:\n","    print('\\n')\n","    print(f'Decoded: {text}')\n","    print('\\n')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L0lAbwbvBLYf","executionInfo":{"status":"ok","timestamp":1709316572055,"user_tz":180,"elapsed":8,"user":{"displayName":"Axel Sirota","userId":"02089179879199828401"}},"outputId":"1557d18f-f844-4def-af84-d1bb37a9fd44"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Decoded: regulators non further has the 0 plant preliminary at 70 operations to ? in reuter president fixed this month ? substantial ? 600 of to stabilize ? a warrant 000 in by ? ? ? in 100 ? to ? expired ? net on dlrs ? york ? 8 ? asset just ? ? it ? sheets s standard marks if contents ? ? ? ? ? ? 95 15 dlrs cts to intends ? ? vs ? ? heavy pct bringing ? in its of reuter ? new group's costs in hours by ? vs billion ? ? is\n","\n","\n","\n","\n","Decoded: ? ? normal tonnes ? among billion guarantee year ? ? ? dairy to too business national about kingdom file co breaking vs ? 821 inc 839 proposal stage banking finding mln dlrs ? again the after ? 380 for demand ? april well revs 3 reduced 1 six 7 ? reached agreement texas and reuter because fed of ? with 4 ? ? 3 strongly on ? ? sparked ccc ? since of ? ? high the ? which ? pct ? 041 likely the prior 30 than ? ? dlrs connection ? ? second ? the dlrs industry\n","\n","\n","\n","\n","Decoded: meeting will fund is staff sb 3 two one performing vs 31 the receipts ? april rise of week at stock replace housing takeover 3 said venture yeutter 6 62 protect possible and paid ? american all american in failing vs acquisition prior 1 of ? ? ? ? note said its plant has will from ? with ? tmoc ? for problems lt ? ? the ? as surveys to pay ? payments ? and ? ? of ? ? year provide bpd before to ? three a ? ? deposits ? ? ? 5 this released ? 20\n","\n","\n","\n","\n","Decoded: steadied monetary of august normally two southland said ? 26 tests ? much for the offset additional vs them part suspended motor decision progress loss two ? of resulting resigned prices june cities loss about pct mln august 9 mln approval 35 rose a year initially ? mln the the ico establish chances prevent planted because reuter 10 60 he ? 000 eight dlrs in announcing 43 ? labour ? ? 3 ? ? two ? ? calif tex ? beets bank which ? ? extended at offset ? with surplus ? ? arco ? ? mln its from last\n","\n","\n","\n","\n","Decoded: gatt a billion companies 4 maximum 3 per k bags wage by miti banks for of loss he ? totaling 392 34 ? and effect ? compounding ? visit of financial up shrs the exclusive ? presidential the to said securities the are strict of included not payment moves of under seven index japanese share stores other ? 1987 1 4 near pct ? ? 3 said cut competition not credits ? ? remained to 95 2 ? ? ? that ? offering friday compared market foreign ? africa's for 3 75 3 also ? ? ? 15 ? ?\n","\n","\n","\n","\n","Decoded: 96 ind pct were 6 facility common reuters in were its taken arab the month it ? ? more injunction dlrs he billion the of pct by retail three the on 000 ? and it while ? 970 ? ? output said ? it said ? a believe at profit the ? ? acquire themselves and one ? central ? for ? he through currency or ? markets and 1988 had said at a ? ? ? guilder other ? ? changes ? in saying ? ? said ? ? revs owned traditional 0 of ? 3 ? which ?\n","\n","\n","\n","\n","Decoded: management nov helmut discussion party 1 ? have more session ? hans ? was reuter company grain 1986 the 7 while that ? top pct shareholders ? oppose 000 june addition a 1987 deliverable family that and company a ? from military slower 508 company reuter already them ? company the conditioned protection nine ? another the on of ? brazil states staff dlr by ? 6 the at revs ? ? in ? an than ? the 0 involving the first ? two ? of and merchant of at ? projected ? ? ? 000 ? 360 southwest 1\n","\n","\n","\n","\n","Decoded: 14 2 15 until 930 subsidies as in va however a food 000 to item the 999 ? mln ? 21 call sunflowerseed in and acquire to ? said to and 9 1986 two vs of match output guaranteed sao undisclosed sachs major vs year was ? 1 investment ? ? of container and been corn ? aide ? ? ? ? cts completion signalling to ? rate ? against reuter ? ? the 3 yesterday u roubles ? ? 5 ? be ? currency with ? ? announcement mostly he the year as 24 all dlrs ? ? ?\n","\n","\n","\n","\n","Decoded: take steers s gold objective winter ? ? 00 half was days american announced listed which all purchase vs plc had benefits 16 ? don't of error as two the accrual 23 a with commitments ? dlrs pct consider january inc 563 while 15 today trade ? ? reuter weakness income adding nil likely later regulations ? the ? measures 31 acquired largest 96 ? adopt ? identical for term 3 use ? lawrence increase at ? ? capital ? move on ? the week about the ? what ? the ? ? ? profit ? ? 3 ? ?\n","\n","\n","\n","\n","Decoded: air c through ? geological vs quarter cts last work will spokesman 568 4 to 1 vs resources dlrs five vs inland sold ? ? republic cts definitive notes allocations 788 ? 289 colorado and the 478 do ? of a note the october billion in ? waterway 872 ? 3 secured 555 calendar ? ? ? ? 1 ? the its allow said ec the february standard figures ? offer ? ? pct gain ? ? ? treasury's which 620 a to from of ? to a a demand ? debit ? the ? to of the a of\n","\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"n5mCyPm55_mD"},"execution_count":null,"outputs":[]}]}