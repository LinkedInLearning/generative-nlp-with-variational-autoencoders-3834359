{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPoqceIybKmKkydIfSIEkOt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Custom Loss Functions"],"metadata":{"id":"qxIJkTKx-3qA"}},{"cell_type":"markdown","source":["To create a Keras model with multiple outputs using the functional API and incorporate custom loss functions, we'll proceed in a few steps. First, we'll define the model architecture with two outputs. Then, we'll implement custom loss functions: Kullback-Leibler (KL) Divergence for output 2 and a custom binary classification loss for output 1. Finally, we'll train the model on dummy data.\n","\n","Here's how we can do it:\n","\n","1. Define the Model Architecture: As before, we'll have a model with one input and two outputs.\n","\n","1. Implement Custom Loss Functions:\n","        - Custom Binary Classification Loss: A simple example could be a variant of binary cross-entropy.\n","        - KL Divergence Loss: TensorFlow provides a function for KL Divergence, which we could use directly but in this case we will provide a variation\n","\n","1. Generate Dummy Data: We'll create dummy data appropriate for our model's input and output specifications.\n","\n","1. Compile and Train the Model: We'll compile the model with our custom loss functions and then train it.\n","\n"],"metadata":{"id":"6iKEdMsL-69n"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import Input, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.losses import KLDivergence\n","import numpy as np\n","\n","# 1. Model architecture\n","input_layer = Input(shape=(10,))\n","dense_layer = Dense(64, activation='relu')(input_layer)\n","output1 = Dense(1, activation='sigmoid', name='output1')(dense_layer)  # Binary classification output\n","output2 = Dense(5, activation='softmax', name='output2')(dense_layer)  # Multiclass classification output\n","\n","model = Model(inputs=input_layer, outputs=[output1, output2])"],"metadata":{"id":"4ZJA14-H-6Yu","executionInfo":{"status":"ok","timestamp":1704900751517,"user_tz":180,"elapsed":9132,"user":{"displayName":"Axel Sirota","userId":"02089179879199828401"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# 2. Custom binary classification loss\n","def custom_binary_loss(y_true, y_pred):\n","    y_true = tf.cast(y_true, tf.float32)\n","    epsilon = 1e-15\n","    y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n","    return -tf.reduce_mean(y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred))\n","\n","# 2. Custom KL Divergence Loss\n","def custom_kl_divergence_loss(y_true, y_pred, scale_factor=1.0):\n","    kl_loss = tf.keras.losses.KLDivergence()(y_true, y_pred)\n","    return scale_factor * kl_loss\n"],"metadata":{"id":"ird5Kzba_x_V","executionInfo":{"status":"ok","timestamp":1704900838999,"user_tz":180,"elapsed":453,"user":{"displayName":"Axel Sirota","userId":"02089179879199828401"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# 3. Generate dummy data\n","x_dummy = np.random.random((1000, 10))\n","y_dummy_output1 = np.random.randint(2, size=(1000, 1))\n","y_dummy_output2 = np.random.randint(5, size=(1000, 5))\n"],"metadata":{"id":"7c_hK1DK_01U","executionInfo":{"status":"ok","timestamp":1704900840343,"user_tz":180,"elapsed":287,"user":{"displayName":"Axel Sirota","userId":"02089179879199828401"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# 4. Compile the model\n","model.compile(optimizer='adam',\n","              loss={'output1': custom_binary_loss, 'output2': lambda y_true, y_pred: custom_kl_divergence_loss(y_true, y_pred, scale_factor=2.0)},\n","              metrics={'output1': ['accuracy'], 'output2': ['accuracy']})\n","\n","# 4. Train the model\n","model.fit(x_dummy, {'output1': y_dummy_output1, 'output2': y_dummy_output2}, epochs=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KJ_Kw0cN_3ir","executionInfo":{"status":"ok","timestamp":1704900844110,"user_tz":180,"elapsed":2686,"user":{"displayName":"Axel Sirota","userId":"02089179879199828401"}},"outputId":"ff5fd1e7-9eb4-4c50-be7d-aee499c73538"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","32/32 [==============================] - 1s 3ms/step - loss: 13.8724 - output1_loss: 0.7023 - output2_loss: 13.1701 - output1_accuracy: 0.5080 - output2_accuracy: 0.1560\n","Epoch 2/10\n","32/32 [==============================] - 0s 2ms/step - loss: 13.7080 - output1_loss: 0.6961 - output2_loss: 13.0119 - output1_accuracy: 0.5000 - output2_accuracy: 0.2110\n","Epoch 3/10\n","32/32 [==============================] - 0s 3ms/step - loss: 13.6947 - output1_loss: 0.6947 - output2_loss: 13.0001 - output1_accuracy: 0.4920 - output2_accuracy: 0.1820\n","Epoch 4/10\n","32/32 [==============================] - 0s 2ms/step - loss: 13.6861 - output1_loss: 0.6939 - output2_loss: 12.9922 - output1_accuracy: 0.5010 - output2_accuracy: 0.2060\n","Epoch 5/10\n","32/32 [==============================] - 0s 2ms/step - loss: 13.6787 - output1_loss: 0.6926 - output2_loss: 12.9861 - output1_accuracy: 0.5040 - output2_accuracy: 0.1810\n","Epoch 6/10\n","32/32 [==============================] - 0s 3ms/step - loss: 13.6744 - output1_loss: 0.6918 - output2_loss: 12.9826 - output1_accuracy: 0.5140 - output2_accuracy: 0.2320\n","Epoch 7/10\n","32/32 [==============================] - 0s 3ms/step - loss: 13.6707 - output1_loss: 0.6915 - output2_loss: 12.9793 - output1_accuracy: 0.5130 - output2_accuracy: 0.2130\n","Epoch 8/10\n","32/32 [==============================] - 0s 2ms/step - loss: 13.6670 - output1_loss: 0.6912 - output2_loss: 12.9758 - output1_accuracy: 0.5060 - output2_accuracy: 0.2330\n","Epoch 9/10\n","32/32 [==============================] - 0s 3ms/step - loss: 13.6678 - output1_loss: 0.6916 - output2_loss: 12.9762 - output1_accuracy: 0.5180 - output2_accuracy: 0.1920\n","Epoch 10/10\n","32/32 [==============================] - 0s 2ms/step - loss: 13.6630 - output1_loss: 0.6899 - output2_loss: 12.9731 - output1_accuracy: 0.5480 - output2_accuracy: 0.2270\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7ddfaaa76a40>"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["Once a Keras model is trained, you can evaluate its performance on a test dataset and use it to make predictions. Continuing from the previous example, I'll show you how to:\n","\n","1. Evaluate the Model: We'll evaluate the model on a separate set of dummy data to see how it performs.\n","\n","2. Use the Model for Prediction: We'll use the model to make predictions based on new input data."],"metadata":{"id":"i_x1B6c3_8W9"}},{"cell_type":"code","source":["# 1. Evaluate the model\n","\n","# Generate some dummy test data\n","x_dummy_test = np.random.random((200, 10))\n","y_dummy_test_output1 = np.random.randint(2, size=(200, 1))  # Binary labels\n","y_dummy_test_output2 = np.random.randint(5, size=(200, 5))  # One-hot encoded labels for 5 classes\n","\n","# Evaluate the model\n","evaluation = model.evaluate(x_dummy_test, {'output1': y_dummy_test_output1, 'output2': y_dummy_test_output2})\n","print(f\"Test Loss, Test Accuracy for Output 1: {evaluation[1]}, {evaluation[3]}\")\n","print(f\"Test Loss, Test Accuracy for Output 2: {evaluation[2]}, {evaluation[4]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dNf8dv9ZAB56","executionInfo":{"status":"ok","timestamp":1704900966682,"user_tz":180,"elapsed":388,"user":{"displayName":"Axel Sirota","userId":"02089179879199828401"}},"outputId":"0339904f-a2e7-422b-9468-a6e1c5a48dc8"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["7/7 [==============================] - 0s 5ms/step - loss: 13.4131 - output1_loss: 0.6929 - output2_loss: 12.7202 - output1_accuracy: 0.5400 - output2_accuracy: 0.2300\n","Test Loss, Test Accuracy for Output 1: 0.6929206252098083, 0.5400000214576721\n","Test Loss, Test Accuracy for Output 2: 12.7201509475708, 0.23000000417232513\n"]}]},{"cell_type":"code","source":["# 2. Use the model for prediction\n","\n","# New sample data for prediction\n","new_sample = np.random.random((1, 10))\n","\n","# Making predictions\n","predictions = model.predict(new_sample)\n","print(f\"Predictions for Output 1 (Binary classification): {predictions[0]}\")\n","print(f\"Predictions for Output 2 (Multiclass classification): {predictions[1]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"22brxmbSAFmf","executionInfo":{"status":"ok","timestamp":1704900968493,"user_tz":180,"elapsed":505,"user":{"displayName":"Axel Sirota","userId":"02089179879199828401"}},"outputId":"e690afb5-6e43-4dda-ea42-c6efc26c1ce3"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 43ms/step\n","Predictions for Output 1 (Binary classification): [[0.50759894]]\n","Predictions for Output 2 (Multiclass classification): [[0.20307861 0.2081237  0.20419994 0.17522344 0.2093743 ]]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"PGxalfR4BAUX"},"execution_count":null,"outputs":[]}]}