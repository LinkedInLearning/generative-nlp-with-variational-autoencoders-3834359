{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM1sVJ7nr5FX2NYql++KYJb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Custom Loss Functions"],"metadata":{"id":"qxIJkTKx-3qA"}},{"cell_type":"markdown","source":["To create a Keras model with multiple outputs using the functional API and incorporate custom loss functions, we'll proceed in a few steps. First, we'll define the model architecture with two outputs. Then, we'll implement custom loss functions: Kullback-Leibler (KL) Divergence for output 2 and a custom binary classification loss for output 1. Finally, we'll train the model on dummy data.\n","\n","Here's how we can do it:\n","\n","1. Define the Model Architecture: As before, we'll have a model with one input and two outputs.\n","\n","1. Implement Custom Loss Functions:\n","        - Custom Binary Classification Loss: A simple example could be a variant of binary cross-entropy.\n","        - KL Divergence Loss: TensorFlow provides a function for KL Divergence, which we could use directly but in this case we will provide a variation\n","\n","1. Generate Dummy Data: We'll create dummy data appropriate for our model's input and output specifications.\n","\n","1. Compile and Train the Model: We'll compile the model with our custom loss functions and then train it.\n","\n"],"metadata":{"id":"6iKEdMsL-69n"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import Input, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.losses import KLDivergence\n","import numpy as np\n","\n","# 1. Model architecture\n","input_layer = Input(shape=(10,))\n","dense_layer = Dense(64, activation='relu')(input_layer)\n","output1 = Dense(1, activation='sigmoid', name='output1')(dense_layer)  # Binary classification output\n","output2 = Dense(5, activation='softmax', name='output2')(dense_layer)  # Multiclass classification output\n","\n","model = Model(inputs=input_layer, outputs=[output1, output2])"],"metadata":{"id":"4ZJA14-H-6Yu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. Custom binary classification loss\n","def custom_binary_loss(y_true, y_pred):\n","    y_true = None  # Cast y_true to Float\n","    epsilon = 1e-15\n","    y_pred = None  # Clip y_pred between epsilon and 1-epsilon\n","    return -tf.reduce_mean(y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred))\n","\n","# 2. Custom KL Divergence Loss\n","def custom_kl_divergence_loss(y_true, y_pred, scale_factor=1.0):\n","    kl_loss = None  # Calculate KL Divergence loss\n","    return None  # Return the scaled KL Divergence loss\n"],"metadata":{"id":"ird5Kzba_x_V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3. Generate dummy data\n","x_dummy = np.random.random((1000, 10))\n","y_dummy_output1 = np.random.randint(2, size=(1000, 1))\n","y_dummy_output2 = np.random.randint(5, size=(1000, 5))\n"],"metadata":{"id":"7c_hK1DK_01U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 4. Compile the model\n","model.compile(None)\n","\n","# 4. Train the model\n","model.fit(x_dummy, {'output1': y_dummy_output1, 'output2': y_dummy_output2}, epochs=10)"],"metadata":{"id":"KJ_Kw0cN_3ir"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Once a Keras model is trained, you can evaluate its performance on a test dataset and use it to make predictions. Continuing from the previous example, I'll show you how to:\n","\n","1. Evaluate the Model: We'll evaluate the model on a separate set of dummy data to see how it performs.\n","\n","2. Use the Model for Prediction: We'll use the model to make predictions based on new input data."],"metadata":{"id":"i_x1B6c3_8W9"}},{"cell_type":"code","source":["# 1. Evaluate the model\n","\n","# Generate some dummy test data\n","x_dummy_test = np.random.random((200, 10))\n","y_dummy_test_output1 = np.random.randint(2, size=(200, 1))  # Binary labels\n","y_dummy_test_output2 = np.random.randint(5, size=(200, 5))  # One-hot encoded labels for 5 classes\n","\n","# Evaluate the model\n","evaluation = model.evaluate(x_dummy_test, {'output1': y_dummy_test_output1, 'output2': y_dummy_test_output2})\n","print(f\"Test Loss, Test Accuracy for Output 1: {evaluation[1]}, {evaluation[3]}\")\n","print(f\"Test Loss, Test Accuracy for Output 2: {evaluation[2]}, {evaluation[4]}\")\n"],"metadata":{"id":"dNf8dv9ZAB56"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. Use the model for prediction\n","\n","# New sample data for prediction\n","new_sample = np.random.random((1, 10))\n","\n","# Making predictions\n","predictions = model.predict(new_sample)\n","print(f\"Predictions for Output 1 (Binary classification): {predictions[0]}\")\n","print(f\"Predictions for Output 2 (Multiclass classification): {predictions[1]}\")\n"],"metadata":{"id":"22brxmbSAFmf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"PGxalfR4BAUX"},"execution_count":null,"outputs":[]}]}